#!/usr/bin/env python
import logging
import random
import string

from twisted.python import log as t_log
from twisted.internet import reactor
from twisted.internet.defer import Deferred, inlineCallbacks

from afkak.client import KafkaClient
from afkak.producer import Producer
from afkak.common import KafkaUnavailableError
from afkak.partitioner import (RoundRobinPartitioner, HashedPartitioner)

log = logging.getLogger(__name__)


# These were stolen from testutil, so you don't need unittest2 installed to
# run the example
def async_delay(timeout=0.01, clock=None):
    if clock is None:
        from twisted.internet import reactor as clock

    timeout = timeout

    def succeed():
        d.callback(timeout)

    d = Deferred()
    clock.callLater(timeout, succeed)
    return d


def random_string(l):
    # Random.choice can be very slow for large amounts of data, so 'cheat'
    if l <= 50:
        s = "".join(random.choice(string.letters) for i in xrange(l))
    else:
        r = random_string(50)
        s = "".join(r for i in xrange(l / 50))
        if l % 50:
            s += r[0:(l % 50)]
    assert len(s) == l
    return s


class ProducerExample(object):

    def __init__(self, topic='example_topic', runtime=60):
        self.topic = topic
        self.runtime = runtime
        self._msgnum = 0
        self._stopping = False
        self._client = KafkaClient("localhost:9092")
        self._producers = []
        self._producers.append(Producer(self._client, RoundRobinPartitioner))
        self._producers.append(Producer(self._client, HashedPartitioner))

    @inlineCallbacks
    def run(self):
        e = True
        try:
            # We do this to auto-create our topic, if needed
            while e:
                yield self._client.load_metadata_for_topics(self.topic)
                e = self._client.metadata_error_for_topic(self.topic)
                if e:
                    log.info("Error: %r getting metadata for topic: %s",
                             e, self.topic)
        except KafkaUnavailableError:
            log.error("Unable to communicate with any Kafka brokers")
            self.stop()

        # Stop ourselves after we've run the allotted time
        reactor.callLater(self.runtime, self.stop)

        def _handle_resp(resp):
            log.info("%r: got response: %r", self, resp)

        def _handle_err(f):
            t_log.err(f)

        while not self._stopping:
            for producer in self._producers:
                # Create some random number of random messages and send them to
                # the current producer
                msgs, key = self._make_messages()
                d = producer.send_messages(self.topic, key=key, msgs=msgs)
                d.addCallbacks(_handle_resp, _handle_err)
            yield async_delay(0.5)

    def stop(self):
        log.info("\n")
        log.info("Time is up, stopping producers...")

        for producer in self._producers:
            producer.stop()

        self._client.close()
        reactor.stop()

    def _make_messages(self):
        # Generate some reasonable (random) number of random messages...
        msgs = []
        for i in range(1, random.randint(2, 25)):
            msgs.append("{0}: {1}".format(self._msgnum, random_string(
                random.randint(20, 40))))
            self._msgnum += 1
        key = random_string(8)
        return (msgs, key)


def main():
    logging.basicConfig(
        format='%(asctime)s:%(name)s:' +
        '%(levelname)s:%(process)d:%(message)s',
        level=logging.DEBUG
        )
    producer_example = ProducerExample(runtime=10)
    reactor.callWhenRunning(producer_example.run)
    reactor.run()
    log.info("All Done!")

if __name__ == "__main__":
    main()
